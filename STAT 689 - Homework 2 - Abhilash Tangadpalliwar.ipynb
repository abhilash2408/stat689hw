{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tangadpalliwar, Abhilash - Homework 2\n",
    "\n",
    "## UIN: 825009793\n",
    "\n",
    "We numerically explore the relationship between error distributions, objective functions (least squares versus least absolute deviation, and computational speed.\n",
    "\n",
    "The following simulation creates a data set according to\n",
    "$$y_i = \\beta_1 + \\beta_2 x_i + \\beta_3 x_i^2 + \\epsilon_i.$$\n",
    "\n",
    "We generate $n$ observations from this model for $x$ on an equally spaced grid $[0,1]$. For $Yt$, the errors ($\\epsilon_i$) have a t-distribution with 2 degrees of freedom. For $Yn$, the errors have a standard normal distribution. We plot each of these data sets and the true regression function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Initializing X matrix\n",
    "\n",
    "rm(list=ls())\n",
    "set.seed(1234)\n",
    "n <- 500\n",
    "x <- seq(from=0,to=1,length.out=n)\n",
    "X <- cbind(1,x,x^2)\n",
    "beta <- matrix(c(1,2,4),nrow=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The t distribution produces a lot of outliers (some outliers are not shown because we restricted the y-axis to ylim in each plot). Given the data, out goal is to infer the parameters $\\beta$. We will consider two methods. The least squares method we discussed in class is\n",
    "$$ \\beta_{LS} = \\text{argmin}_{\\beta} (y_i - \\beta_1 - \\beta_2 x_i - \\beta_3 x_i^2)^2 =  \\text{argmin}_{\\beta} (Y - X\\beta)^T(Y - X\\beta) = (X^TX)^{-1}X^TY$$\n",
    "A second possibility is to find the [least absolute deviations](https://en.wikipedia.org/wiki/Least_absolute_deviations) estimator. We call this $\\beta_{LAD}$ which has the form\n",
    "$$\\beta_{LAD} = \\text{argmin}_{\\beta} |y_i - \\beta_1 - \\beta_2 x_i - \\beta_3 x_i^2|.$$\n",
    "This may also be known as $L_1$ regression or quantile regression with the $0.5$ quantile.\n",
    "\n",
    "In this homework you will fit both $\\beta_{LS}$ and $\\beta_{LAD}$ and compare the methods based on parameter estimation accuracy and speed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 1\n",
    "\n",
    "Fixing $X$, generate the $Yt$ and $Yn$ data $N=100$ times (note that $n$ is the sample size and $N$ is the number of times we run the simulation). Compute $\\beta_{LS}$ and $\\beta_{LAD}$ each time. Since $\\beta$ is a vector of length $3$, this will result in 4 matrices (LS for $Yt$ and $Yn$ and LAD for $Yt$ and $Yn$) with $N$ rows and 3 columns (you could store this output in other formats as well, but matrices are convenient).\n",
    "\n",
    "Make scatterplots of $\\beta_2$ versus $\\beta_3$ estimates for each type of data, estimator. This will produce four scatterplots. Mark the true $\\beta_2$ and $\\beta_3$ on each plot and comment of the quality of the estimators in the different settings. Your scatterplot should look similar to the ones below.\n",
    "\n",
    "**Tips for Fitting** For fitting $\\beta_{LS}$, you have many options in R (lm, lm.fit) and python (scipy.linalg.lstsq, sklearn.linear_model.LinearRegression). For fitting $\\beta_{LAD}$ in R you can use l1fit from the package L1pack or  rq.fit from quantreg. For fitting $\\beta_{LAD}$ in python the options are somewhat more limited:\n",
    "* [statsmodels](http://www.statsmodels.org/dev/examples/notebooks/generated/quantile_regression.html) requires use of pandas, calls the quantreg R package\n",
    "* generic optimizer such as [scipy.optimize](https://docs.scipy.org/doc/scipy/reference/tutorial/optimize.html)\n",
    "\n",
    "The later is a more general method that will likely be slower. But scipy.optimize is general and will be useful for many other problems. You may also use any other optimizer you find. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Creating Y matrices for normal and t-distribution\n",
    "\n",
    "Yt=matrix(,nrow=500,ncol=100)\n",
    "Yn=matrix(,nrow=500,ncol=100)\n",
    "\n",
    "N=100\n",
    "\n",
    "for (i in 1:N) \n",
    "    {Yt[,i] <- X%*%beta + rt(n,df=2)\n",
    "     Yn[,i] <- X%*%beta + rnorm(n)\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Creating output matrices for storing Least Squares models' co-effecients\n",
    "\n",
    "output.tdist.ls=matrix(,nrow=3,ncol=100)\n",
    "output.norm.ls=matrix(,nrow=3,ncol=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<tbody>\n",
       "\t<tr><td>1.041848</td><td>2.261006</td><td>1.590283</td><td>2.929542</td><td>1.495795</td><td>2.198842</td><td>1.729554</td><td>1.722652</td><td>2.124522</td><td>1.951365</td><td>...     </td><td>3.054081</td><td>1.808778</td><td>1.835004</td><td>1.681578</td><td>1.824431</td><td>1.441117</td><td>2.383978</td><td>1.728558</td><td>1.666153</td><td>2.501480</td></tr>\n",
       "\t<tr><td>4.937847</td><td>3.675706</td><td>4.574074</td><td>3.146503</td><td>4.397912</td><td>4.107873</td><td>4.114616</td><td>4.276174</td><td>3.747158</td><td>3.950136</td><td>...     </td><td>2.981855</td><td>3.957672</td><td>4.306578</td><td>4.218495</td><td>4.142001</td><td>4.901088</td><td>3.651192</td><td>4.498422</td><td>4.195881</td><td>3.584995</td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "\\begin{tabular}{llllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllll}\n",
       "\t 1.041848 & 2.261006 & 1.590283 & 2.929542 & 1.495795 & 2.198842 & 1.729554 & 1.722652 & 2.124522 & 1.951365 & ...      & 3.054081 & 1.808778 & 1.835004 & 1.681578 & 1.824431 & 1.441117 & 2.383978 & 1.728558 & 1.666153 & 2.501480\\\\\n",
       "\t 4.937847 & 3.675706 & 4.574074 & 3.146503 & 4.397912 & 4.107873 & 4.114616 & 4.276174 & 3.747158 & 3.950136 & ...      & 2.981855 & 3.957672 & 4.306578 & 4.218495 & 4.142001 & 4.901088 & 3.651192 & 4.498422 & 4.195881 & 3.584995\\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "| 1.041848 | 2.261006 | 1.590283 | 2.929542 | 1.495795 | 2.198842 | 1.729554 | 1.722652 | 2.124522 | 1.951365 | ...      | 3.054081 | 1.808778 | 1.835004 | 1.681578 | 1.824431 | 1.441117 | 2.383978 | 1.728558 | 1.666153 | 2.501480 | \n",
       "| 4.937847 | 3.675706 | 4.574074 | 3.146503 | 4.397912 | 4.107873 | 4.114616 | 4.276174 | 3.747158 | 3.950136 | ...      | 2.981855 | 3.957672 | 4.306578 | 4.218495 | 4.142001 | 4.901088 | 3.651192 | 4.498422 | 4.195881 | 3.584995 | \n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "     [,1]     [,2]     [,3]     [,4]     [,5]     [,6]     [,7]     [,8]    \n",
       "[1,] 1.041848 2.261006 1.590283 2.929542 1.495795 2.198842 1.729554 1.722652\n",
       "[2,] 4.937847 3.675706 4.574074 3.146503 4.397912 4.107873 4.114616 4.276174\n",
       "     [,9]     [,10]    [,11] [,12]    [,13]    [,14]    [,15]    [,16]   \n",
       "[1,] 2.124522 1.951365 ...   3.054081 1.808778 1.835004 1.681578 1.824431\n",
       "[2,] 3.747158 3.950136 ...   2.981855 3.957672 4.306578 4.218495 4.142001\n",
       "     [,17]    [,18]    [,19]    [,20]    [,21]   \n",
       "[1,] 1.441117 2.383978 1.728558 1.666153 2.501480\n",
       "[2,] 4.901088 3.651192 4.498422 4.195881 3.584995"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Least Squares estimates for normally distributed Y\n",
    "\n",
    "for (i in 1:N)\n",
    "    {model1=lm.fit(X,Yn[,i])\n",
    "     output.norm.ls[,i]=model1$coefficients\n",
    "     }\n",
    "output.norm.ls=output.norm.ls[-1,]\n",
    "output.norm.ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<tbody>\n",
       "\t<tr><td>1.429478 </td><td>2.793093 </td><td>0.865696 </td><td>1.645431 </td><td>-1.190960</td><td>0.8219021</td><td>1.795423 </td><td>1.398424 </td><td>0.4010152</td><td>4.5784988</td><td>...      </td><td>3.039165 </td><td>-0.612499</td><td>1.232164 </td><td>4.75005  </td><td>2.099493 </td><td>1.602425 </td><td>3.218409 </td><td>2.620318 </td><td>2.88716  </td><td>1.014557 </td></tr>\n",
       "\t<tr><td>4.908305 </td><td>2.465236 </td><td>4.702245 </td><td>4.011904 </td><td> 7.152541</td><td>5.0863323</td><td>3.948903 </td><td>5.023896 </td><td>5.9398561</td><td>0.5935827</td><td>...      </td><td>3.951976 </td><td> 6.065665</td><td>4.364515 </td><td>1.08183  </td><td>3.206995 </td><td>3.887144 </td><td>2.591478 </td><td>3.202033 </td><td>3.20407  </td><td>4.362286 </td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "\\begin{tabular}{llllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllll}\n",
       "\t 1.429478  & 2.793093  & 0.865696  & 1.645431  & -1.190960 & 0.8219021 & 1.795423  & 1.398424  & 0.4010152 & 4.5784988 & ...       & 3.039165  & -0.612499 & 1.232164  & 4.75005   & 2.099493  & 1.602425  & 3.218409  & 2.620318  & 2.88716   & 1.014557 \\\\\n",
       "\t 4.908305  & 2.465236  & 4.702245  & 4.011904  &  7.152541 & 5.0863323 & 3.948903  & 5.023896  & 5.9398561 & 0.5935827 & ...       & 3.951976  &  6.065665 & 4.364515  & 1.08183   & 3.206995  & 3.887144  & 2.591478  & 3.202033  & 3.20407   & 4.362286 \\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "| 1.429478  | 2.793093  | 0.865696  | 1.645431  | -1.190960 | 0.8219021 | 1.795423  | 1.398424  | 0.4010152 | 4.5784988 | ...       | 3.039165  | -0.612499 | 1.232164  | 4.75005   | 2.099493  | 1.602425  | 3.218409  | 2.620318  | 2.88716   | 1.014557  | \n",
       "| 4.908305  | 2.465236  | 4.702245  | 4.011904  |  7.152541 | 5.0863323 | 3.948903  | 5.023896  | 5.9398561 | 0.5935827 | ...       | 3.951976  |  6.065665 | 4.364515  | 1.08183   | 3.206995  | 3.887144  | 2.591478  | 3.202033  | 3.20407   | 4.362286  | \n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "     [,1]     [,2]     [,3]     [,4]     [,5]      [,6]      [,7]     [,8]    \n",
       "[1,] 1.429478 2.793093 0.865696 1.645431 -1.190960 0.8219021 1.795423 1.398424\n",
       "[2,] 4.908305 2.465236 4.702245 4.011904  7.152541 5.0863323 3.948903 5.023896\n",
       "     [,9]      [,10]     [,11] [,12]    [,13]     [,14]    [,15]   [,16]   \n",
       "[1,] 0.4010152 4.5784988 ...   3.039165 -0.612499 1.232164 4.75005 2.099493\n",
       "[2,] 5.9398561 0.5935827 ...   3.951976  6.065665 4.364515 1.08183 3.206995\n",
       "     [,17]    [,18]    [,19]    [,20]   [,21]   \n",
       "[1,] 1.602425 3.218409 2.620318 2.88716 1.014557\n",
       "[2,] 3.887144 2.591478 3.202033 3.20407 4.362286"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Least Squares estimates for t-distributed Y\n",
    "\n",
    "for (i in 1:N)\n",
    "    {model2=lm.fit(X,Yt[,i])\n",
    "     output.tdist.ls[,i]=model2$coefficients\n",
    "     }\n",
    "output.tdist.ls=output.tdist.ls[-1,]\n",
    "output.tdist.ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Installing package into 'C:/Users/abhil/OneDrive/Documents/R/win-library/3.4'\n",
      "(as 'lib' is unspecified)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "package 'L1pack' successfully unpacked and MD5 sums checked\n",
      "\n",
      "The downloaded binary packages are in\n",
      "\tC:\\Users\\abhil\\AppData\\Local\\Temp\\RtmpaciXCN\\downloaded_packages\n"
     ]
    }
   ],
   "source": [
    "install.packages('L1pack',repos = \"http://cran.us.r-project.org\")\n",
    "library(L1pack)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Creating output matrices for storing LAD models' co-effecients\n",
    "\n",
    "output.tdist.lad=matrix(,nrow=3,ncol=100)\n",
    "output.norm.lad=matrix(,nrow=3,ncol=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<tbody>\n",
       "\t<tr><td>1.184128 </td><td>2.112981 </td><td>1.581694 </td><td>3.362733 </td><td>1.729299 </td><td>1.876089 </td><td>0.7438341</td><td>1.560867 </td><td>2.264751 </td><td>2.387233 </td><td>...      </td><td>2.848107 </td><td>1.523551 </td><td>1.764893 </td><td>1.466702 </td><td>1.585434 </td><td>1.800327 </td><td>2.221047 </td><td>1.510229 </td><td>2.377080 </td><td>3.367978 </td></tr>\n",
       "\t<tr><td>4.716541 </td><td>3.826161 </td><td>4.630109 </td><td>2.795545 </td><td>4.236143 </td><td>4.686106 </td><td>4.8329720</td><td>4.143104 </td><td>3.618114 </td><td>3.417345 </td><td>...      </td><td>3.067234 </td><td>4.103059 </td><td>4.324073 </td><td>4.365107 </td><td>4.230564 </td><td>4.497593 </td><td>3.675118 </td><td>4.801352 </td><td>3.584168 </td><td>2.592739 </td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "\\begin{tabular}{llllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllll}\n",
       "\t 1.184128  & 2.112981  & 1.581694  & 3.362733  & 1.729299  & 1.876089  & 0.7438341 & 1.560867  & 2.264751  & 2.387233  & ...       & 2.848107  & 1.523551  & 1.764893  & 1.466702  & 1.585434  & 1.800327  & 2.221047  & 1.510229  & 2.377080  & 3.367978 \\\\\n",
       "\t 4.716541  & 3.826161  & 4.630109  & 2.795545  & 4.236143  & 4.686106  & 4.8329720 & 4.143104  & 3.618114  & 3.417345  & ...       & 3.067234  & 4.103059  & 4.324073  & 4.365107  & 4.230564  & 4.497593  & 3.675118  & 4.801352  & 3.584168  & 2.592739 \\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "| 1.184128  | 2.112981  | 1.581694  | 3.362733  | 1.729299  | 1.876089  | 0.7438341 | 1.560867  | 2.264751  | 2.387233  | ...       | 2.848107  | 1.523551  | 1.764893  | 1.466702  | 1.585434  | 1.800327  | 2.221047  | 1.510229  | 2.377080  | 3.367978  | \n",
       "| 4.716541  | 3.826161  | 4.630109  | 2.795545  | 4.236143  | 4.686106  | 4.8329720 | 4.143104  | 3.618114  | 3.417345  | ...       | 3.067234  | 4.103059  | 4.324073  | 4.365107  | 4.230564  | 4.497593  | 3.675118  | 4.801352  | 3.584168  | 2.592739  | \n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "     [,1]     [,2]     [,3]     [,4]     [,5]     [,6]     [,7]      [,8]    \n",
       "[1,] 1.184128 2.112981 1.581694 3.362733 1.729299 1.876089 0.7438341 1.560867\n",
       "[2,] 4.716541 3.826161 4.630109 2.795545 4.236143 4.686106 4.8329720 4.143104\n",
       "     [,9]     [,10]    [,11] [,12]    [,13]    [,14]    [,15]    [,16]   \n",
       "[1,] 2.264751 2.387233 ...   2.848107 1.523551 1.764893 1.466702 1.585434\n",
       "[2,] 3.618114 3.417345 ...   3.067234 4.103059 4.324073 4.365107 4.230564\n",
       "     [,17]    [,18]    [,19]    [,20]    [,21]   \n",
       "[1,] 1.800327 2.221047 1.510229 2.377080 3.367978\n",
       "[2,] 4.497593 3.675118 4.801352 3.584168 2.592739"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#LAD estimates for normally distributed Y\n",
    "\n",
    "for (i in 1:N)\n",
    "    {model3=l1fit(X[,-1],Yn[,i])\n",
    "     output.norm.lad[,i]=model3$coefficients\n",
    "     }\n",
    "output.norm.lad=output.norm.lad[-1,]\n",
    "output.norm.lad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<tbody>\n",
       "\t<tr><td>0.7141812</td><td>1.329642 </td><td>1.029709 </td><td>1.444682 </td><td>0.9020346</td><td>1.279075 </td><td>2.237942 </td><td>0.4915196</td><td>1.479725 </td><td>2.941448 </td><td>...      </td><td>2.787849 </td><td>0.1914572</td><td>1.598888 </td><td>2.105967 </td><td>0.5812809</td><td>1.930582 </td><td>3.830879 </td><td>2.356669 </td><td>1.792396 </td><td>0.7805264</td></tr>\n",
       "\t<tr><td>5.1952181</td><td>4.712879 </td><td>4.536510 </td><td>4.749768 </td><td>5.4633331</td><td>4.878817 </td><td>3.642538 </td><td>5.4204407</td><td>4.699656 </td><td>2.745446 </td><td>...      </td><td>3.461375 </td><td>5.8963914</td><td>4.661741 </td><td>3.490656 </td><td>4.9884171</td><td>3.364551 </td><td>2.410777 </td><td>3.495471 </td><td>4.171587 </td><td>5.1232772</td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "\\begin{tabular}{llllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllll}\n",
       "\t 0.7141812 & 1.329642  & 1.029709  & 1.444682  & 0.9020346 & 1.279075  & 2.237942  & 0.4915196 & 1.479725  & 2.941448  & ...       & 2.787849  & 0.1914572 & 1.598888  & 2.105967  & 0.5812809 & 1.930582  & 3.830879  & 2.356669  & 1.792396  & 0.7805264\\\\\n",
       "\t 5.1952181 & 4.712879  & 4.536510  & 4.749768  & 5.4633331 & 4.878817  & 3.642538  & 5.4204407 & 4.699656  & 2.745446  & ...       & 3.461375  & 5.8963914 & 4.661741  & 3.490656  & 4.9884171 & 3.364551  & 2.410777  & 3.495471  & 4.171587  & 5.1232772\\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "| 0.7141812 | 1.329642  | 1.029709  | 1.444682  | 0.9020346 | 1.279075  | 2.237942  | 0.4915196 | 1.479725  | 2.941448  | ...       | 2.787849  | 0.1914572 | 1.598888  | 2.105967  | 0.5812809 | 1.930582  | 3.830879  | 2.356669  | 1.792396  | 0.7805264 | \n",
       "| 5.1952181 | 4.712879  | 4.536510  | 4.749768  | 5.4633331 | 4.878817  | 3.642538  | 5.4204407 | 4.699656  | 2.745446  | ...       | 3.461375  | 5.8963914 | 4.661741  | 3.490656  | 4.9884171 | 3.364551  | 2.410777  | 3.495471  | 4.171587  | 5.1232772 | \n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "     [,1]      [,2]     [,3]     [,4]     [,5]      [,6]     [,7]     [,8]     \n",
       "[1,] 0.7141812 1.329642 1.029709 1.444682 0.9020346 1.279075 2.237942 0.4915196\n",
       "[2,] 5.1952181 4.712879 4.536510 4.749768 5.4633331 4.878817 3.642538 5.4204407\n",
       "     [,9]     [,10]    [,11] [,12]    [,13]     [,14]    [,15]    [,16]    \n",
       "[1,] 1.479725 2.941448 ...   2.787849 0.1914572 1.598888 2.105967 0.5812809\n",
       "[2,] 4.699656 2.745446 ...   3.461375 5.8963914 4.661741 3.490656 4.9884171\n",
       "     [,17]    [,18]    [,19]    [,20]    [,21]    \n",
       "[1,] 1.930582 3.830879 2.356669 1.792396 0.7805264\n",
       "[2,] 3.364551 2.410777 3.495471 4.171587 5.1232772"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#LAD estimates for t-distributed Y\n",
    "\n",
    "for (i in 1:N)\n",
    "    {model4=l1fit(X[,-1],Yt[,i])\n",
    "     output.tdist.lad[,i]=model4$coefficients\n",
    "     }\n",
    "output.tdist.lad=output.tdist.lad[-1,]\n",
    "output.tdist.lad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA0gAAANICAMAAADKOT/pAAAAM1BMVEUAAABNTU1oaGh8fHyM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\ngEgAAiASgACIBCDA/yMPp8WOI3tYAAAAAElFTkSuQmCC",
      "text/plain": [
       "Plot with title \"LAD - Normal Errors\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plotting the coeffecients obtained from the 4 models above against the true co-effecients \n",
    "\n",
    "par(mfrow=c(2,2))\n",
    "\n",
    "# For t-distributed Y\n",
    "ylim <- c(0,11)\n",
    "xlim <- c(-10,10)\n",
    "\n",
    "plot(output.tdist.ls[1,],output.tdist.ls[2,],xlab=\"Beta_1\",ylab=\"Beta_2\",main=\"LS - t Errors\",xlim=xlim,ylim=ylim)\n",
    "points(2,4, col=\"red1\", pch=19, cex=1.5)\n",
    "plot(output.tdist.lad[1,],output.tdist.lad[2,],xlab=\"Beta_1\",ylab=\"Beta_2\",main=\"LAD - t Errors\",xlim=xlim,ylim=ylim)\n",
    "points(2,4, col=\"red1\", pch=19, cex=1.5)\n",
    "\n",
    "# For normally distributed Y\n",
    "\n",
    "ylim <- c(0,7)\n",
    "xlim <- c(0,5)\n",
    "\n",
    "plot(output.norm.ls[1,],output.norm.ls[2,],xlab=\"Beta_1\",ylab=\"Beta_2\",main=\"LS - Normal Errors\",xlim=xlim,ylim=ylim)\n",
    "points(2,4, col=\"red1\", pch=19, cex=1.5)\n",
    "plot(output.norm.lad[1,],output.norm.lad[2,],xlab=\"Beta_1\",ylab=\"Beta_2\",main=\"LAD - Normal Errors\",xlim=xlim,ylim=ylim)\n",
    "points(2, 4, col=\"red1\", pch=19, cex=1.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "As it is evident from the graphs above, we can comment that for t-distributed errors, LAD model seems to be of better quality than LS model as the values of the co-effecients are closer to the true co-effecients.\n",
    "\n",
    "In case of normally distributed errors, least squares model appears to be of a better quality than LAD model as the values of the co-effecients are closer to the true co-effecients, though the quality of the fit is not as good as LAD model for t-distributed errors."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 2\n",
    "\n",
    "Compare the speed of $\\beta_{LS}$ to $\\beta_{LAD}$ using a package such as benchmark in R or some of the tools [here](https://jakevdp.github.io/PythonDataScienceHandbook/01.07-timing-and-profiling.html) in python. Empirically determine the computational complexity (in $n$) of $\\beta_{LAD}$ and $\\beta_{LS}$ (we know from theoretical analysis that $\\widehat{\\beta}_{LS}$ should be linear in $n$)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Installing package into 'C:/Users/abhil/OneDrive/Documents/R/win-library/3.4'\n",
      "(as 'lib' is unspecified)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "package 'rbenchmark' successfully unpacked and MD5 sums checked\n",
      "\n",
      "The downloaded binary packages are in\n",
      "\tC:\\Users\\abhil\\AppData\\Local\\Temp\\RtmpaciXCN\\downloaded_packages\n"
     ]
    }
   ],
   "source": [
    "install.packages('rbenchmark',repos = \"http://cran.us.r-project.org\")\n",
    "library(rbenchmark)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# running replications for determining computational complexities \n",
    "\n",
    "times =  benchmark( \"LS using lm.fit\" = {\n",
    "            for (i in 1:N)\n",
    "                lm.fit(X,Yn[,i])\n",
    "     \n",
    "            },\n",
    "           \n",
    "           \"LAD using l1fit\" = {\n",
    "            for (i in 1:N)\n",
    "                l1fit(X[,-1],Yt[,i])\n",
    "            },replications=c(5,10,20,40,80,160,320,640,1280,2560), columns=c('test', 'elapsed', 'replications'), order='test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA0gAAANICAMAAADKOT/pAAAANlBMVEUAAAAA/wBNTU1oaGh8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\nIUGAkCDgP6cHGoRV2p7oAAAAAElFTkSuQmCC",
      "text/plain": [
       "plot without title"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot(replications,elapsed,type=\"p\",col=c(\"red\",\"green\")[test], pch=19, \n",
    "     xlab = \"Replications\", ylab = \"Elapsed Time\");\n",
    "legend(x=\"topleft\", legend = levels(test), col=c(\"red\",\"green\"), pch=19);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead><tr><th></th><th scope=col>test</th><th scope=col>elapsed</th><th scope=col>replications</th></tr></thead>\n",
       "<tbody>\n",
       "\t<tr><th scope=row>2</th><td>LAD using l1fit</td><td> 0.15          </td><td>   5           </td></tr>\n",
       "\t<tr><th scope=row>4</th><td>LAD using l1fit</td><td> 0.29          </td><td>  10           </td></tr>\n",
       "\t<tr><th scope=row>6</th><td>LAD using l1fit</td><td> 0.61          </td><td>  20           </td></tr>\n",
       "\t<tr><th scope=row>8</th><td>LAD using l1fit</td><td> 1.11          </td><td>  40           </td></tr>\n",
       "\t<tr><th scope=row>10</th><td>LAD using l1fit</td><td> 2.24          </td><td>  80           </td></tr>\n",
       "\t<tr><th scope=row>12</th><td>LAD using l1fit</td><td> 4.55          </td><td> 160           </td></tr>\n",
       "\t<tr><th scope=row>14</th><td>LAD using l1fit</td><td> 9.11          </td><td> 320           </td></tr>\n",
       "\t<tr><th scope=row>16</th><td>LAD using l1fit</td><td>17.99          </td><td> 640           </td></tr>\n",
       "\t<tr><th scope=row>18</th><td>LAD using l1fit</td><td>35.67          </td><td>1280           </td></tr>\n",
       "\t<tr><th scope=row>20</th><td>LAD using l1fit</td><td>71.60          </td><td>2560           </td></tr>\n",
       "\t<tr><th scope=row>1</th><td>LS using lm.fit</td><td> 0.06          </td><td>   5           </td></tr>\n",
       "\t<tr><th scope=row>3</th><td>LS using lm.fit</td><td> 0.08          </td><td>  10           </td></tr>\n",
       "\t<tr><th scope=row>5</th><td>LS using lm.fit</td><td> 0.15          </td><td>  20           </td></tr>\n",
       "\t<tr><th scope=row>7</th><td>LS using lm.fit</td><td> 0.34          </td><td>  40           </td></tr>\n",
       "\t<tr><th scope=row>9</th><td>LS using lm.fit</td><td> 0.58          </td><td>  80           </td></tr>\n",
       "\t<tr><th scope=row>11</th><td>LS using lm.fit</td><td> 1.21          </td><td> 160           </td></tr>\n",
       "\t<tr><th scope=row>13</th><td>LS using lm.fit</td><td> 2.38          </td><td> 320           </td></tr>\n",
       "\t<tr><th scope=row>15</th><td>LS using lm.fit</td><td> 4.75          </td><td> 640           </td></tr>\n",
       "\t<tr><th scope=row>17</th><td>LS using lm.fit</td><td> 9.58          </td><td>1280           </td></tr>\n",
       "\t<tr><th scope=row>19</th><td>LS using lm.fit</td><td>19.07          </td><td>2560           </td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "\\begin{tabular}{r|lll}\n",
       "  & test & elapsed & replications\\\\\n",
       "\\hline\n",
       "\t2 & LAD using l1fit &  0.15           &    5           \\\\\n",
       "\t4 & LAD using l1fit &  0.29           &   10           \\\\\n",
       "\t6 & LAD using l1fit &  0.61           &   20           \\\\\n",
       "\t8 & LAD using l1fit &  1.11           &   40           \\\\\n",
       "\t10 & LAD using l1fit &  2.24           &   80           \\\\\n",
       "\t12 & LAD using l1fit &  4.55           &  160           \\\\\n",
       "\t14 & LAD using l1fit &  9.11           &  320           \\\\\n",
       "\t16 & LAD using l1fit & 17.99           &  640           \\\\\n",
       "\t18 & LAD using l1fit & 35.67           & 1280           \\\\\n",
       "\t20 & LAD using l1fit & 71.60           & 2560           \\\\\n",
       "\t1 & LS using lm.fit &  0.06           &    5           \\\\\n",
       "\t3 & LS using lm.fit &  0.08           &   10           \\\\\n",
       "\t5 & LS using lm.fit &  0.15           &   20           \\\\\n",
       "\t7 & LS using lm.fit &  0.34           &   40           \\\\\n",
       "\t9 & LS using lm.fit &  0.58           &   80           \\\\\n",
       "\t11 & LS using lm.fit &  1.21           &  160           \\\\\n",
       "\t13 & LS using lm.fit &  2.38           &  320           \\\\\n",
       "\t15 & LS using lm.fit &  4.75           &  640           \\\\\n",
       "\t17 & LS using lm.fit &  9.58           & 1280           \\\\\n",
       "\t19 & LS using lm.fit & 19.07           & 2560           \\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "| <!--/--> | test | elapsed | replications | \n",
       "|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|\n",
       "| 2 | LAD using l1fit |  0.15           |    5            | \n",
       "| 4 | LAD using l1fit |  0.29           |   10            | \n",
       "| 6 | LAD using l1fit |  0.61           |   20            | \n",
       "| 8 | LAD using l1fit |  1.11           |   40            | \n",
       "| 10 | LAD using l1fit |  2.24           |   80            | \n",
       "| 12 | LAD using l1fit |  4.55           |  160            | \n",
       "| 14 | LAD using l1fit |  9.11           |  320            | \n",
       "| 16 | LAD using l1fit | 17.99           |  640            | \n",
       "| 18 | LAD using l1fit | 35.67           | 1280            | \n",
       "| 20 | LAD using l1fit | 71.60           | 2560            | \n",
       "| 1 | LS using lm.fit |  0.06           |    5            | \n",
       "| 3 | LS using lm.fit |  0.08           |   10            | \n",
       "| 5 | LS using lm.fit |  0.15           |   20            | \n",
       "| 7 | LS using lm.fit |  0.34           |   40            | \n",
       "| 9 | LS using lm.fit |  0.58           |   80            | \n",
       "| 11 | LS using lm.fit |  1.21           |  160            | \n",
       "| 13 | LS using lm.fit |  2.38           |  320            | \n",
       "| 15 | LS using lm.fit |  4.75           |  640            | \n",
       "| 17 | LS using lm.fit |  9.58           | 1280            | \n",
       "| 19 | LS using lm.fit | 19.07           | 2560            | \n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "   test            elapsed replications\n",
       "2  LAD using l1fit  0.15      5        \n",
       "4  LAD using l1fit  0.29     10        \n",
       "6  LAD using l1fit  0.61     20        \n",
       "8  LAD using l1fit  1.11     40        \n",
       "10 LAD using l1fit  2.24     80        \n",
       "12 LAD using l1fit  4.55    160        \n",
       "14 LAD using l1fit  9.11    320        \n",
       "16 LAD using l1fit 17.99    640        \n",
       "18 LAD using l1fit 35.67   1280        \n",
       "20 LAD using l1fit 71.60   2560        \n",
       "1  LS using lm.fit  0.06      5        \n",
       "3  LS using lm.fit  0.08     10        \n",
       "5  LS using lm.fit  0.15     20        \n",
       "7  LS using lm.fit  0.34     40        \n",
       "9  LS using lm.fit  0.58     80        \n",
       "11 LS using lm.fit  1.21    160        \n",
       "13 LS using lm.fit  2.38    320        \n",
       "15 LS using lm.fit  4.75    640        \n",
       "17 LS using lm.fit  9.58   1280        \n",
       "19 LS using lm.fit 19.07   2560        "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# displaying the experimental results\n",
    "\n",
    "times"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Empirical determination of computational complexity\n",
    "\n",
    "According to the experimental results and the graph above, the computational complexities of both LS and LAD estimates\n",
    "of beta seem to be of order (n) as both of the graphs follow a linear trend with the number of replications. \n",
    "\n",
    "However, LAD estimates take more time to compute (approximately 3-4 times) as compared to LS estimates, implying that the constant associated with LAD is thrice or four times that of LS."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "3.4.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
